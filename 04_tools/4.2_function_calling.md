## 4.2 函数调用 详解

### 4.2.1 打破次元壁：从 Chatbot 到 Agent

ChatGPT 发布初期，最令人诟病的一点是“它不知道刚才发生的新闻”和“它不能帮我点外卖”。这是因为 LLM 是被封印在服务器显卡里的“缸中之脑”，它无法联网，也无法操作文件系统。

**工具使用 (Tool Use)**，或者在 OpenAI 体系中称为 **Function Calling**，彻底打破了这堵墙。它赋予了 Agent “手”和“脚”，使其能够执行 API 调用、运行代码、控制浏览器，从而真正地干涉物理和数字世界。

---

#### 深度解析 Function Calling 机制

Function Calling 并不是魔法，它本质上是一种**结构化输出协议**。模型并没有真的去运行 Python 函数，它只是生成了一段**请求运行函数**的文本。

#### 定义工具
为了让 Agent 使用工具，我们必须先用精确的语言定义工具。通常使用 JSON Schema 或 Pydantic 模型。
*   **Name**：工具的唯一标识，如 `get_weather`。
*   **Description**：**这是最重要的部分**。LLM 依靠这段描述来判断何时调用该工具。描述模糊会导致调用失败或幻觉。
    *   *Bad*: `func(a, b)`
    *   *Good*: `calculate_mortgage(principal, rate, years)`: "根据本金、年利率和年限计算每月房贷还款额。"
*   **Parameters**：参数的类型、是否必填、枚举值等。

#### 推理与生成的循环
当用户说“查询北京明天的天气”时：
1.  **Thinking**: LLM 分析语义，发现需要外部数据。
2.  **Selection**: LLM 扫描工具列表，发现 `get_weather` 最相关。
3.  **Generation**: LLM 输出一个特殊的 JSON 结构：
    ```json
    {
      "tool_calls": [
        {
          "id": "call_123",
          "function": {
            "name": "get_weather",
            "arguments": "{\"location\": \"Beijing\", \"date\": \"tomorrow\"}"
          }
        }
      ]
    }
    ```
4.  **Execution (Runtime)**: 我们的 Python 脚本（Runtime）解析这个 JSON，在本地真正调用 `get_weather("Beijing", "tomorrow")` 函数，获取返回值 `"Sunny, 25C"`.
5.  **Feedback**: Runtime 构建一条 `ToolMessage`，包含返回值，追加到对话历史中，再次喂给 LLM。
6.  **Response**: LLM 看到最新的 ToolMessage，终于可以说：“北京明天晴朗，气温 25 度。”

---

### 4.2.2 常用工具类别与实战

一个全能的 Agent 通常通过 **Toolkit** 的形式加载一组工具：

#### 信息获取类
*   **Web Search (Google/Bing/DuckDuckGo)**: 解决 LLM 知识截止和时效性问题。
*   **Wikipedia**: 获取背景知识。
*   **Arxiv**: 搜索学术论文。
*   **RAG Retriever**: 搜索私有的企业知识库。

#### 数理逻辑类
LLM 是文科生，算数（Arithmetic）很差，经常一本正经地算错。
*   **Calculator**: 简单的四则运算。
*   **Python Interpreter**: 终极武器。当需要解方程、数据分析、画图时，让 Agent 写一段 Python 代码并在沙箱中运行，是准确率最高的方法（OpenAI Code Interpreter 模式）。

#### 生产力工具类
*   **Gmail/Outlook**:读写邮件。
*   **Calendar**: 安排日程。
*   **Jira/Trello**: 管理项目任务。
*   **File System**: 读写本地文件（需严格限制路径）。

---

### 4.2.3 鲁棒性与安全设计

给 AI 配枪（工具），必须要有保险栓。

#### 容错设计
*   **幻觉参数 (Hallucinated Args)**：LLM 可能会编造不存在的参数名。代码层必须做 Schema 校验（Pydantic），如果校验失败，将错误信息（Validation Error）直接返给 LLM，让它**自我修正**。
*   **工具报错**：如果 API 超时或报错，Agent 不应崩溃，而应捕获异常，并尝试重试或换一个工具。

#### 安全沙箱
*   **Code Execution Risks**: 永远不要在主进程中直接 `exec()` Agent 生成的代码。它可能包含 `os.system("rm -rf /")`。
*   **解决方案**：使用 Docker 容器、E2B 沙箱或 WebAssembly 环境来隔离运行不可信代码。
*   **Human-in-the-loop**: 对于敏感操作（转账、发邮件、删文件），必须设置**人工确认**环节。Agent 生成操作请求，人类点击“批准”后，系统才真正执行。

### 4.2.4 结构化输出

结构化输出（Structured Outputs）是 Function Calling 的增强版本，能够**保证** API 响应严格匹配预定义的 JSON Schema。

#### 解决的问题

传统的 Function Calling 存在格式不稳定问题：

```python
# 传统方式：模型可能返回不符合 Schema 的数据
response = agent.run("提取用户信息")
# 可能返回：{"name": "张三"} 而非预期的 {"full_name": "张三", "age": null}
```

结构化输出通过约束解码（Constrained Decoding）保证输出 100% 符合 Schema：

```python
# 结构化输出：保证格式正确
response = agent.run(
    "提取用户信息",
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "user_info",
            "schema": {
                "type": "object",
                "properties": {
                    "full_name": {"type": "string"},
                    "age": {"type": ["integer", "null"]}
                },
                "required": ["full_name", "age"]
            }
        }
    }
)
# 保证返回：{"full_name": "张三", "age": null}
```

#### 关键应用场景

| 场景 | 说明 |
|------|------|
| **数据提取** | 下游系统依赖无错误、一致的格式 |
| **多 Agent 架构** | Agent 间通信格式一致性是性能和稳定性的关键 |
| **复杂搜索工具** | 多字段必须精确填充并符合特定模式 |

#### 收益

1. **消除解析错误**：无需 try-catch 和重试逻辑
2. **简化代码**：移除复杂的失败回退处理
3. **提升可靠性**：生产环境中工具调用成功率接近 100%

> [!TIP]
> Claude 的结构化输出已在 Sonnet 4.5 和 Opus 4.1 上公测，详见 [Claude Structured Outputs 文档](https://docs.claude.com/en/docs/build-with-claude/structured-outputs)

---

### 4.2.5 高级工具使用特性

随着 Agent 需要调用的工具数量从几个扩展到数十甚至上百个，传统的工具调用方式面临严峻挑战。Anthropic 在 2025 年底发布了三个高级特性来解决这些问题。

#### Tool Search Tool（工具搜索工具）

**问题**：当连接多个 MCP 服务器时，工具定义的 Token 消耗急剧增长：

| 服务器 | 工具数 | Token 消耗 |
|--------|--------|-----------|
| GitHub | 35 | ~26K |
| Slack | 11 | ~21K |
| Jira | 10+ | ~17K |
| 合计 | 50+ | 100K+ |

这意味着对话还没开始，上下文窗口就已经消耗了大量空间。

**解决方案**：不预先加载所有工具定义，而是让 Agent 按需发现工具。

```python
# 传统方式：所有工具预加载 (~72K tokens)
tools = [github_tools + slack_tools + jira_tools + ...]

# Tool Search Tool：仅加载搜索工具 (~500 tokens)
tools = [
    {"type": "tool_search_tool_regex", "name": "search_tools"},
    # 其他工具标记为 defer_loading: true
]
```

**效果**：
- Token 使用减少 85%
- Opus 4 工具选择准确率从 49% 提升到 74%
- Opus 4.5 准确率从 79.5% 提升到 88.1%

#### Programmatic Tool Calling（编程式工具调用）

**问题**：传统工具调用的两个瓶颈：
1. **上下文污染**：分析 10MB 日志文件时，整个文件进入上下文
2. **推理开销**：每次工具调用需要一次完整的模型推理

**解决方案**：让 Agent 用代码编排工具调用，而不是逐个请求。

```python
# 传统方式：20 次工具调用 + 20 次推理
for member in team:
    expenses = get_expenses(member.id)  # 每次返回到模型上下文
    # 2000+ 条费用记录进入上下文...

# 编程式调用：1 次代码执行
code = """
expenses = await asyncio.gather(*[
    get_expenses(m['id']) for m in team
])
exceeded = [m for m, e in zip(team, expenses) 
            if sum(e) > budget]
print(json.dumps(exceeded))  # 仅最终结果进入上下文
"""
```

**效果**：
- Token 消耗减少 37%
- 知识检索准确率从 25.6% 提升到 28.5%
- GAIA 基准从 46.5% 提升到 51.2%

#### Tool Use Examples（工具使用示例）

**问题**：JSON Schema 只能定义结构有效性，无法表达使用模式：
- 何时包含可选参数？
- 哪些参数组合有意义？
- API 期望哪些约定？

**解决方案**：提供规范的工具使用示例。

```json
{
  "name": "search_database",
  "description": "搜索客户数据库",
  "input_schema": {...},
  "examples": [
    {
      "description": "按名称模糊搜索",
      "input": {"query": "张%", "limit": 10},
      "output": "[{\"id\": 1, \"name\": \"张三\"}...]"
    },
    {
      "description": "精确匹配 + 日期过滤",
      "input": {"query": "李四", "exact": true, "after": "2024-01-01"}
    }
  ]
}
```

> [!TIP]
> **何时使用这些特性**：
> - **Tool Search**：工具定义超过 10K tokens，或有 10+ 工具
> - **Programmatic Calling**：涉及批量数据处理或多步编排
> - **Tool Examples**：工具用法复杂，Schema 无法完整表达

---

### 4.2.6 本节小结

[**Toolformer**](https://arxiv.org/abs/2302.04761) 的出现标志着 Agent 开始学会使用工具。通过精心设计的 Schema 和鲁棒的 Runtime，我们将 LLM 从聊天窗口解放出来，使其成为了能够操作万物的万能接口。工具使用能力的强弱，直接决定了 Agent 的落地价值。

---

**下一节**: [MCP：模型上下文协议](4.3_mcp.md)