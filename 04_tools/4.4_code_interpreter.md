## 4.4 代码解释器与沙箱环境

**代码解释器 (Code Interpreter)** 是 Agentic AI 进化史上最重要的里程碑之一。它让 LLM 从"说话者"变成了"行动者"。不仅仅是写出代码，更是**运行**代码，让 Agent 具备了计算、分析数据甚至绘图的能力。

本节深入探讨代码解释器的原理、实现方式以及至关重要的安全沙箱设计。

#### 为什么 LLM 需要代码解释器

#### 1. 弥补数学短板
LLM 本质上是基于概率的 Token 预测机。问它 "248 * 1923 等于多少"，它可能会通过模式匹配猜一个大致正确的数字，但很容易出错。
- **Without Interpreter**: 猜数字，易幻觉。
- **With Interpreter**: 写一句 `print(248 * 1923)`，运行，得到 100% 正确的结果。

#### 2. 精确数据分析
处理一个 100MB 的 CSV 文件，LLM 的上下文窗口塞不下，且难以精确统计。
代码解释器允许 Agent 写 Pandas 代码来读取、清洗、聚合数据，只返回统计结果。

#### 3. 多模态输出能力
LLM 只能输出 Token。但通过代码解释器，Agent 可以调用 Matplotlib 画图，调用 MoviePy 剪视频，生成 .docx / .xlsx 文件。

#### 工作原理

代码解释器的核心是一个**REPL (Read-Eval-Print Loop)** 循环。

```python
# Agent 的思维过程
Thought: 用户想知道斐波那契数列第 50 项。这不能口算。
Action: RunPython("""
def fib(n):
    a, b = 0, 1
    for _ in range(n):
        a, b = b, a + b
    return a

print(fib(50))
""")
# --- Environment Execution ---
Observation: 12586269025
Answer: 斐波那契数列第 50 项是 12586269025。
```

### 4.4.1 安全沙箱设计 (Sandboxing)

**代码解释器是把双刃剑**。赋予 Agent 行动力的同时也引入了巨大的安全风险。如果用户让 Agent 运行 `import os; os.system('rm -rf /')`，后果不堪设想。

因此，代码解释器**必须且只能**运行在严格隔离的沙箱中。

#### 1. Docker 容器隔离

这是最通用的行业标准方案。

- **实现**：
  为每个 Session 启动一个独立的 Docker 容器。容器内预装 Python, Pandas, Numpy 等常用库。
- **资源限制**：
  - CPU: 限制核心数
  - Memory: 限制 512MB，防止内存溢出攻击
  - Network: **默认禁用网络**，防止数据外泄或发起网络攻击。
- **生命周期**：
  任务结束后立即销毁容器。

```python
import docker

client = docker.from_env()

def run_code_in_docker(code: str):
    container = client.containers.run(
        image="python-sandbox:latest",
        command=["python3", "-c", code],
        mem_limit="512m",
        network_disabled=True,
        detach=False,
        remove=True  # 运行完即焚
    )
    return container.decode("utf-8")
```

#### 2. 云原生沙箱 (Cloud MicroVMs)

对于生产环境，Docker 启动速度（秒级）可能太慢。E2B 等公司利用 Firecracker MicroVM 技术提供毫秒级启动的沙箱 API。

```python
from e2b import Sandbox

def analyze_data_securely(data_url, query):
    # 启动一个云端沙箱，拥有独立的文件系统
    sandbox = Sandbox.create(template="data-analysis")
    
    # 1. 下载数据
    sandbox.filesystem.write("data.csv", download(data_url))
    
    # 2. Agent 生成代码
    code = llm.generate_code(query)
    
    # 3. 远程执行
    output = sandbox.run_code(code)
    
    # 4. 获取生成的文件（如图表）
    if output.png_data:
        save_image(output.png_data)
        
    sandbox.close()
    return output.logs
```

#### 3. WebAssembly (WASM)

最轻量级的方案。直接在浏览器端或 Node.js 中通过 Pyodide 运行 Python。
- **优点**：零服务器成本，绝对安全（代码跑在用户自己的浏览器里）。
- **缺点**：性能较弱，无法加载大型 C 扩展库。

### 4.4.2 文件系统管理

代码解释器不仅仅是运行代码，还需要管理文件。
Agent 需要理解 `/mnt/data` 这种虚拟路径的概念。

- **上传**：用户传文件 -> 存入沙箱 ->告诉 Agent 文件路径。
- **下载**：Agent 生成文件 (`plt.savefig('plot.png')`) -> 从沙箱读出 -> 返回给用户下载链接。

### 4.4.3 小结

代码解释器是 Agent 的"左脑"，负责逻辑、计算和精确执行。
在设计自己的 Agent 系统时，强烈建议集成代码解释器能力，但切记：**Security First**。永远不要在宿主机直接运行 LLM 生成的代码。

下一节我们将探讨 Agent 的多模态感知能力。

---

**下一节**: [多模态感知与行动](4.5_multimodal.md)