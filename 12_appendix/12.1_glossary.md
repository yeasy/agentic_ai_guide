## 12.1 术语表

本书中出现的关键术语及其解释。

### 12.1.1 术语翻译约定

| 英文术语 | 中文翻译 | 本书写法 |
|---------|---------|---------|
| Agent | 智能体 | 智能体 或 智能体 (Agent) |
| Token | 词元 | Token（代码/技术讨论中保留英文） |
| Prompt | 提示词 | 提示词 或 提示词 (Prompt) |
| Context | 上下文 | 上下文 |
| Embedding | 嵌入向量 | 嵌入 或 嵌入向量 |
| Hallucination | 幻觉 | 幻觉 |
| Fine-tuning | 微调 | 微调 |
| RAG | 检索增强生成 | RAG |

---

### 12.1.2 A

**Agent (智能体)**: 具有自主决策能力的 AI 系统，能够感知环境、制定计划并执行行动以达成目标。

**Agent-to-Agent Protocol (A2A, 智能体对智能体协议)**: 一类用于智能体间通信和协作的协议标准。

**Agent Card (智能体名片)**: A2A 协议中智能体发布的自我描述文档，包含身份和能力信息。

**Artificial General Intelligence (AGI, 通用人工智能)**: 具有人类水平通用智能的 AI 系统。

**Alignment (对齐)**: 确保 AI 系统的行为与人类意图和价值观一致的过程。

**Agentic Coding (智能体编程)**: AI 作为自主开发伙伴参与软件开发的新范式。

**Agentic Workflow (智能体工作流)**: AI 以迭代、自主方式完成复杂任务的工作模式。

**Agentic Development Maturity Model (智能体研发成熟度模型)**: 一种用于描述研发模式演进的分级框架：L1 辅助、L2 协同、L3 自主。

### 12.1.3 C

**Chain-of-Thought (CoT, 思维链)**: 让模型在给出答案前展示推理步骤的技术。

**Computer Use (计算机使用)**: AI 直接控制鼠标、键盘操作桌面环境的能力。

**Context Engineering (上下文工程)**: 管理大语言模型有限“注意力预算”的学科，比提示词工程更广泛。

**Context Window (上下文窗口)**: 模型一次能处理的最大词元 (Token) 数量。

**Compounding Engineering (复利工程)**: 通过知识沉淀使智能体系统持续进化的工程方法。

### 12.1.4 D

**Deliberative Alignment (审慎对齐)**: 推理模型在思维链中显式调用安全原则的技术。

### 12.1.5 E

**Embedding (嵌入向量)**: 将文本转换为高维向量表示，用于语义相似度计算。

### 12.1.6 F

**Function Calling (函数调用)**: 模型生成结构化的函数调用请求，由外部系统执行。

**Few-Shot Learning (少样本学习)**: 通过少量示例让模型学会新任务的技术。

### 12.1.7 G

**Graph of Thoughts (GoT, 思维图)**: 将推理过程组织为图结构的高级推理技术。

### 12.1.8 H

**Hallucination (幻觉)**: 模型生成看似合理但实际错误的信息。

**Human-in-the-Loop (HITL, 人在回路)**: 在 AI 决策过程中保留人类参与和审批的设计模式。

**Hooks (钩子)**: 在工具或框架的生命周期事件中注入自定义逻辑的机制。

### 12.1.9 L

**Large Multimodal Model (LMM, 大型多模态模型)**: 能处理文本、图像、音频等多种输入的模型。

### 12.1.10 M

**Memory Poisoning (记忆投毒)**: 间接提示词注入的一种变种，旨在污染智能体的长期记忆（例如向量检索知识库）。

**Multi-Agent (多智能体)**: 多个 AI 智能体协作完成任务的系统架构。

### 12.1.11 P

**Perceive-Plan-Act Loop (PPA, 感知-规划-行动循环)**: 智能体的基本工作循环。

**Plan Mode (规划模式)**: 智能体先制定计划再执行的工作模式。

**Prompt Engineering (提示词工程)**: 设计有效提示词以引导模型产生期望输出的技术。

### 12.1.12 R

**Retrieval-Augmented Generation (RAG, 检索增强生成)**: 通过检索外部知识增强生成质量。

**ReAct (推理与行动)**: 将推理和行动交织进行的智能体架构模式。

**Reflexion (反思)**: 让智能体从失败中学习并改进的机制。

**Reinforcement Learning from Human Feedback (RLHF, 基于人类反馈的强化学习)**: 使用人类偏好数据优化模型的训练方法。

**Rules (规则)**: 存储在项目规则目录中的项目级行为规范。

**Reasoners (推理模型)**: 在复杂任务上表现更稳定、更擅长多步推理的一类模型，是智能体系统能力提升的重要来源。

### 12.1.13 S

**Sandbox (沙箱)**: 隔离执行环境，防止代码对系统造成危害。

**Skills (技能)**: 封装领域知识的可复用知识包。

**Standard Operating Procedure (SOP, 标准操作流程)**: 预定义的工作流程。

**Stop Sequence (停止序列)**: 控制模型暂停生成、等待工具结果的特殊标记。

### 12.1.14 T

**Token (词元)**: 模型处理的基本文本单位，一个汉字约 1-2 个词元。

**Model Context Protocol (MCP, 模型上下文协议)**: 一类用于模型与工具交互的开放协议标准。

**Tool Use (工具使用)**: 智能体调用外部工具扩展能力的能力。

**Tree of Thoughts (ToT, 思维树)**: 将推理过程组织为树结构的推理技术。

**Trajectory (轨迹)**: 智能体完成任务的完整执行路径，包含所有思考和行动。

### 12.1.15 V

**Vibe Coding (氛围编程)**: 用自然语言描述需求、由 AI 生成代码的编程风格。

**Vector Database (向量数据库)**: 专门存储和检索向量的数据库系统。

### 12.1.16 Z

**Zero-Shot (零样本)**: 不提供示例，仅通过指令让模型完成任务。

---

**下一节**: [推荐论文与阅读清单](12.2_reading_list.md)
