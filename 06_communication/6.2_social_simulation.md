## 6.2 生成式社会模拟：斯坦福小镇解析

2023 年，斯坦福大学发布的 [Generative Agents](https://arxiv.org/abs/2304.03442) 论文震撼了 AI 社区。研究者创建了一个虚拟小镇，25 个 AI 居民在其中自主生活、工作、社交，展现出令人惊叹的"类人"行为。本节将深入解析这一里程碑式的**生成式智能体（Generative Agents）**研究。

### 6.2.1 斯坦福小镇概述

### 6.2.2 实验设计

斯坦福小镇（Smallville）是一个像素风格的虚拟环境，包含：

- **25 个 AI 居民**：每人有姓名、职业、性格、人际关系
- **虚拟空间**：咖啡馆、公园、住宅、办公室等场所
- **时间系统**：模拟日夜循环，居民按作息生活
- **交互机制**：居民可以对话、协作、建立关系

**核心发现**：当给每个 Agent 足够的记忆和反思能力时，复杂的社会行为会自然涌现。

#### 涌现行为示例

研究中观察到的惊人行为：

1. **自发组织派对**：一位 Agent 决定举办生日派对，自己发邀请、安排时间，其他 Agent 自发讨论是否参加
2. **信息传播**：一条八卦从 A 传到 B，再传到 C，形成真实的社交网络
3. **情感记忆**：失恋的 Agent 会避开前任经常出没的地点
4. **协作计划**：多个 Agent 讨论并共同筹备市长选举活动

### 6.2.3 核心技术架构

#### 记忆流

每个 Agent 维护一个时间顺序的记忆流，记录所有观察和行为：

```python
class MemoryStream:
    def __init__(self):
        self.memories = []  # 按时间顺序存储
        
    def add_memory(
        self, 
        description: str,
        timestamp: datetime,
        importance: float  # 0-10 的重要性评分
    ):
        memory = {
            "description": description,
            "timestamp": timestamp,
            "importance": importance,
            "embedding": embed(description),
            "access_count": 0,
            "last_access": timestamp
        }
        self.memories.append(memory)
```

**记忆检索三要素**：

| 要素 | 说明 | 计算方式 |
|------|------|----------|
| 相关性 (Relevance) | 与当前情境的语义相似度 | Embedding（嵌入） 余弦相似度 |
| 近因性 (Recency) | 越近的记忆越重要 | 指数衰减函数 |
| 重要性 (Importance) | 事件的显著程度 | LLM 打分 (0-10) |

```python
def retrieve_memories(
    self, 
    query: str, 
    k: int = 10
) -> List[Memory]:
    query_embedding = embed(query)
    
    scored_memories = []
    for memory in self.memories:
        # 相关性分数
        relevance = cosine_similarity(query_embedding, memory["embedding"])
        
        # 近因性分数（指数衰减）
        hours_passed = (now() - memory["timestamp"]).total_seconds() / 3600
        recency = 0.99 ** hours_passed
        
        # 重要性分数（归一化）
        importance = memory["importance"] / 10
        
        # 综合评分
        score = relevance + recency + importance
        scored_memories.append((memory, score))
    
    # 返回 top-k
    scored_memories.sort(key=lambda x: x[1], reverse=True)
    return [m for m, s in scored_memories[:k]]
```

#### 反思机制

Agent 定期"反思"自己的记忆，生成更高层次的抽象认知：

```python
async def reflect(self) -> List[str]:
    # 检索最近的重要记忆
    recent_memories = self.retrieve_memories(
        query="最近发生了什么重要的事？",
        k=100
    )
    
    # 提取关键问题
    questions_prompt = f"""
    基于以下记忆，提出 3 个值得深入思考的问题：
    
    记忆：
    {format_memories(recent_memories)}
    """
    questions = await llm.generate(questions_prompt)
    
    # 对每个问题进行反思
    insights = []
    for question in questions:
        relevant_memories = self.retrieve_memories(question, k=20)
        
        insight_prompt = f"""
        问题：{question}
        
        相关记忆：
        {format_memories(relevant_memories)}
        
        基于这些记忆，你能得出什么结论或洞察？
        """
        insight = await llm.generate(insight_prompt)
        
        # 将洞察作为新记忆存储（高重要性）
        self.add_memory(
            description=f"反思：{insight}",
            timestamp=now(),
            importance=8  # 反思通常很重要
        )
        insights.append(insight)
        
    return insights
```

**反思示例**：

```
记忆片段：
- 早上和 Maria 在咖啡馆聊天
- Maria 提到她最近很忙
- 下午看到 Maria 独自在公园散步，看起来很累

反思结论：
"Maria 最近压力很大，可能需要朋友的支持。下次见面应该主动关心她。"
```

#### 规划系统

每个 Agent 每天会生成日程计划，并根据实际情况动态调整：

```python
async def create_daily_plan(self, agent: Agent) -> List[PlanItem]:
    # 获取 Agent 的背景信息
    persona = agent.persona
    
    plan_prompt = f"""
    角色：{persona.name}
    职业：{persona.occupation}
    今日日期：{today()}
    
    {persona.name} 的典型日程是什么样的？
    请用简洁的方式列出今天从早到晚的活动计划。
    
    格式：
    时间 | 地点 | 活动
    """
    
    raw_plan = await llm.generate(plan_prompt)
    return parse_plan(raw_plan)
```

**规划的层次性**：

```
高层计划（一天）：
  08:00 - 起床、洗漱
  09:00 - 去咖啡馆工作
  12:00 - 午餐
  ...
  
中层计划（一小时）：
  09:00 - 到达咖啡馆
  09:10 - 点咖啡
  09:20 - 打开笔记本开始写作
  ...
  
低层行动（即时）：
  走向咖啡馆入口 → 开门 → 走到柜台 → 点单 → ...
```

### 6.2.4 对话与社交

### 6.2.5 自然的对话生成

当两个 Agent 相遇时，系统会判断是否需要对话：

```python
async def should_initiate_conversation(
    agent1: Agent, 
    agent2: Agent,
    context: str
) -> bool:
    # 检索与对方相关的记忆
    memories_about = agent1.retrieve_memories(
        query=f"关于 {agent2.name} 的记忆",
        k=5
    )
    
    prompt = f"""
    {agent1.name} 刚刚看到了 {agent2.name}。
    
    关于 {agent2.name} 的记忆：
    {format_memories(memories_about)}
    
    当前情境：{context}
    
    {agent1.name} 应该主动打招呼吗？回答 Yes 或 No，并说明理由。
    """
    
    response = await llm.generate(prompt)
    return "yes" in response.lower()
```

### 6.2.6 对话内容生成

对话基于双方的记忆和性格生成：

```python
async def generate_dialogue(
    speaker: Agent,
    listener: Agent,
    conversation_history: List[str]
) -> str:
    # 获取相关记忆
    relevant_memories = speaker.retrieve_memories(
        query=f"与 {listener.name} 的对话",
        k=10
    )
    
    prompt = f"""
    说话者：{speaker.name} ({speaker.persona.traits})
    听者：{listener.name}
    
    相关记忆：
    {format_memories(relevant_memories)}
    
    对话历史：
    {format_history(conversation_history)}
    
    {speaker.name} 接下来会说什么？请保持符合角色性格。
    """
    
    return await llm.generate(prompt)
```

#### 技术启示

### 6.2.7 对 Agent 开发的影响

斯坦福小镇的研究为我们提供了重要启示：

1. **记忆是关键**：足够丰富的**记忆流（Memory Stream）**系统是复杂行为涌现的基础
2. **反思产生智慧**：定期反思让 Agent 能够形成抽象认知
3. **规划带来连贯性**：分层规划让行为更加自然和有目的
4. **简单规则，复杂涌现**：不需要硬编码复杂行为，让其自然涌现

#### 局限性与挑战

- **计算成本高**：每个 Agent 每天需要数千次 LLM 调用
- **一致性维护困难**：长时间运行后可能出现人设偏离
- **评估标准模糊**：如何量化"社会行为的真实性"？

### 6.2.8 小结

斯坦福小镇证明了一个重要假设：**当 AI Agent 具备足够的记忆、反思和规划能力时，复杂的社会行为可以自然涌现**。这不仅是一次技术演示，更是对 AI 社会模拟前沿的重要探索。

> 论文链接：[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442)
> 
> 代码仓库：[joonspk-research/generative_agents](https://github.com/joonspk-research/generative_agents)

下一节我们将探讨博弈论在多智能体系统中的应用。

---

**下一节**: [6.3 Game Theory](6.3_game_theory.md)