## 2.4 反思与自我修正

反思 (Reflexion) 是一种让智能体从自身经验中学习并持续改进的机制。它模拟了人类“反思-总结-改进”的认知过程，是实现自主学习智能体的关键技术。

> [!NOTE] 术语说明
> 在智能体 AI 领域，**Reflexion**通常特指 Shinn 等人提出的“基于语言反馈的强化学习”框架 (Reflexion framework)，而通用英语单词**Reflection** 指的是更广泛的“反思”认知能力。本书主要探讨这种机制，因此沿用学术界常用的 Reflexion 一词，但也涵盖广泛的反思 (Reflection) 能力。

### 2.4.1 什么是反思

反思 (Reflexion) 框架由 Noah Shinn 等人在论文 [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/abs/2303.11366) 中提出。反思的本质是让智能体 **在任务失败后进行自我反思，将失败经验转化为可复用的语言形式知识（而非模型权重更新）**。

```
尝试 → 失败 → 反思（为什么失败？）→ 总结（学到了什么？）→ 将语言记忆注入下一次尝试
```

### 2.4.2 与人类学习的类比

| 阶段 | 人类学习 | 反思智能体 |
|------|----------|-----------------|
| 尝试 | 做数学题 | 执行任务 |
| 反馈 | 发现答案错误 | 收到失败信号 |
| 反思 | “我是在哪一步算错了？” | 分析错误原因 |
| 总结 | “以后要注意检查符号” | 生成经验总结 |
| 改进 | 下次做题更仔细 | 更新策略/记忆 |

### 2.4.3 反思的三要素

#### 执行者

负责执行任务的智能体，通常采用 ReAct 模式：

```python
class Actor:
    def act(self, task: str, memory: List[str]) -> Trajectory:
        """
        执行任务，返回执行轨迹
        memory: 之前反思得到的经验
        """
        prompt = f"""
        任务：{task}
        
        之前的经验教训：
        {format_memories(memory)}
        
        请执行任务...
        """
        return execute_with_react(prompt)
```

#### 评估者

判断任务是否成功：

```python
class Evaluator:
    def evaluate(self, trajectory: Trajectory, ground_truth: Any) -> Tuple[bool, str]:
        """
        评估执行结果
        返回：(是否成功, 反馈信息)
        """
        result = trajectory.final_result
        
        if matches(result, ground_truth):
            return True, "任务完成"
        else:
            return False, f"结果不正确，预期 {ground_truth}，实际 {result}"
```

#### 反思者

从失败中提取经验：

```python
class SelfReflection:
    def reflect(self, task: str, trajectory: Trajectory, feedback: str) -> str:
        """
        分析失败原因，生成经验总结
        """
        prompt = f"""
        任务：{task}
        
        执行轨迹：
        {format_trajectory(trajectory)}
        
        失败反馈：{feedback}
        
        请分析：
        1. 在哪个步骤出了问题？
        2. 为什么会出这个问题？
        3. 下次应该如何避免？
        
        请用一句话总结这次的经验教训：
        """
        return model.generate(prompt)
```

### 2.4.4 完整的 Reflexion 循环

```python
def reflexion_loop(task: str, max_trials: int = 3):
    memory = []  # 存储反思经验
    
    for trial in range(max_trials):
        # 1. 执行任务（带着记忆）

        trajectory = actor.act(task, memory)
        
        # 2. 评估结果

        success, feedback = evaluator.evaluate(trajectory)
        
        # 3. 如果成功，返回结果

        if success:
            return trajectory.final_result
        
        # 4. 如果失败，进行反思

        reflection = self_reflection.reflect(task, trajectory, feedback)
        memory.append(reflection)
        
        print(f"Trial {trial + 1} 失败，反思结果：{reflection}")
    
    return "达到最大尝试次数，任务失败"
```

#### 实际应用示例：代码编写任务

**任务**：编写一个函数计算斐波那契数列第 n 项

**第一次尝试**：
```python
def fibonacci(n):
    return fibonacci(n-1) + fibonacci(n-2)  # ❌ 缺少终止条件
```

**评估结果**：`RecursionError: maximum recursion depth exceeded`

**反思**：
> “这次失败是因为递归函数没有设置终止条件（base case），导致无限递归。下次编写递归函数时，必须首先定义 base case。”

**第二次尝试**（带着反思记忆）：
```python
def fibonacci(n):
    if n <= 1:  # ✅ 添加了 base case
        return n
    return fibonacci(n-1) + fibonacci(n-2)
```

**评估结果**：`通过！`

### 2.4.5 记忆管理策略

#### 短期记忆（滑动窗口）

只保留最近 k 次反思：

```python
class ShortTermMemory:
    def __init__(self, max_size: int = 5):
        self.memories = deque(maxlen=max_size)
    
    def add(self, reflection: str):
        self.memories.append(reflection)
```

#### 长期记忆（持久化存储）

将反思结果存入向量数据库进行持久化存储，以便在未来的任务中复用：

```python
class LongTermMemory:
    def __init__(self, vector_store):
        self.store = vector_store
    
    def add(self, reflection: str, task_type: str):
        embedding = embed(reflection)
        self.store.add(embedding, metadata={"text": reflection, "type": task_type})
    
    def retrieve(self, current_task: str, k: int = 3) -> List[str]:
        """检索与当前任务相关的历史经验"""
        return self.store.search(embed(current_task), top_k=k)
```

#### 经验泛化

从具体经验中提取通用规则，并注入到系统提示词中作为全局准则：

```
具体经验：
- "计算阶乘时忘了处理 n=0 的情况"
- "递归求和时没有设置终止条件"
- "链表遍历时没有检查空指针"

泛化规则：
→ "处理递归或循环结构时，始终先确定边界条件和终止条件"
```

**实现方式**：

```python
def consolidate_memories(memory_store):
    """定期执行的内存整理任务"""
    # 1. 聚类相似的错误记录

    clusters = cluster_similar_errors(memory_store.fetch_all())
    
    for cluster in clusters:
        # 2. 提取通用规则

        rule = model.generate(f"基于以下失败案例总结一条通用原则：\n{cluster}")
        
        # 3. 注入到系统提示词中作为全局准则

        agent.update_system_prompt(add_rule=rule)
```

### 2.4.6 与其他技术的结合

#### Reflexion + ReAct

ReAct 提供行动能力，Reflexion 提供学习能力。

```python
# ReAct 提供行动能力，Reflexion 提供学习能力

class ReflexiveReActAgent:
    def run(self, task):
        for trial in range(max_trials):
            # ReAct 风格的执行

            trajectory = self.react_loop(task)
            
            if self.is_success(trajectory):
                return trajectory.result
            
            # Reflexion 风格的学习

            reflection = self.reflect(trajectory)
            self.memory.add(reflection)
```

#### Reflexion + Tool Learning

从工具使用失败中学习，并更新工具使用知识库。

```
反思："调用 search API 时参数格式错误，应该用 {'q': query} 而不是 {'query': query}"
→ 更新工具使用知识库
```

### 2.4.7 评估 Reflexion 的效果

#### 最小实验

为了准确评估反思机制的效果，工程上应当建立对齐原论文精神的测试基准。以下是一个针对代码生成任务（如 HumanEval 基准）的最小复现实验设定：

- **评估任务**：HumanEval（如 Python 函数补全）。
- **核心指标**：`pass@1`（无反思的单次通过率）对比引入 Reflexion 循环后的最终通过率。
- **最大尝试次数（Max Trials）**：通常严格设置为 3 至 5 次（超过此阈值容易产生幻觉累积或成本衰减）。
- **反馈来源（Feedback Type）**：
  - 代码执行反馈：沙箱执行模型生成的单元测试或真实测试用例（包括通过/失败状态及报错堆栈追踪）。
  - 裁判模型反馈：由另一个隔离的 LLM 实例作为客观裁判，对初步答案给出判定和缺陷描述。
- **记忆结构与注入策略**：将失败输出、报错日志和反思总结组装为结构化数据包（参考 [第3章](../03_memory/README.md) 的统一上下文结构），在下一次尝试时强置于编排提示词的末尾。

#### 关键评估指标

| 指标 | 说明 |
|------|------|
| 成功率提升 | 第 n 次尝试的成功率与第 1 次对比 |
| 尝试次数 | 平均需要多少次才能成功 |
| 反思质量 | 反思是否正确定位问题 |
| 知识迁移 | 一个任务的经验是否帮助另一个 |

#### 实验结果（参考论文）

部分研究在代码生成等任务上报告：引入 Reflexion 循环（多次尝试 + 反馈 + 经验总结）后，整体通过率会有明显提升。需要注意：不同模型、提示词、评测脚本与尝试次数都会显著影响数值，文中不固定引用具体百分比。

### 2.4.8 局限性与注意事项

- **评估信号的质量**：反思依赖准确的评估信号。如果评估不准确，反思也会出错。
- **反思的准确性**：模型可能错误归因失败原因，导致“错误的经验教训”。
- **计算成本**：多次尝试意味着多次模型调用，成本较高。
- **适用场景**：最适合有明确成功标准的任务（如代码、数学题），对于开放性任务效果有限。

---

**下一节**: [智能体提示词工程](2.5_prompt_engineering.md)
