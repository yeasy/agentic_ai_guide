## 2.1 思维链与复杂推理

思维链（Chain-of-Thought, CoT）是让大语言模型展现复杂推理能力的关键技术。它通过引导模型"逐步思考"，显著提升了 AI 在数学、逻辑、编程等任务上的表现。

### 2.1.1 什么是思维链

#### 核心思想

思维链的本质是让模型**在给出最终答案之前，先输出中间推理步骤**。

**传统 Prompt**：
```
Q: 一个农场有 15 只羊，卖掉 6 只后又买了 4 只，现在有多少只羊？
A: 13 只
```

**使用 CoT**：
```
Q: 一个农场有 15 只羊，卖掉 6 只后又买了 4 只，现在有多少只羊？
A: 让我一步步来思考：
   1. 初始羊的数量：15 只
   2. 卖掉 6 只后：15 - 6 = 9 只
   3. 又买了 4 只：9 + 4 = 13 只
   因此，现在有 13 只羊。
```

#### 为什么有效

1. **降低认知负荷**：将复杂问题分解为简单步骤
2. **错误可追溯**：每一步都可验证
3. **激活相关知识**：中间步骤触发更多相关推理
4. **对齐人类思维**：模仿人类解决问题的方式

### 2.1.2 CoT 的主要变体

#### Zero-Shot CoT

最简单的形式，只需添加**"Let's think step by step"**：

```python
prompt = f"""
{question}

Let's think step by step.
"""
```

**优点**：无需示例，通用性强
**缺点**：质量不如 Few-Shot 稳定

#### Few-Shot CoT

提供包含推理过程的示例：

```python
prompt = """
Q: 小明有 5 个苹果，小红给了他 3 个，他吃了 2 个。现在有几个？
A: 让我一步步分析：
   - 初始：5 个
   - 收到：5 + 3 = 8 个
   - 吃掉：8 - 2 = 6 个
   答案：6 个苹果

Q: 一筐橘子有 24 个，平均分给 6 个人，每人得几个？
A: 让我一步步分析：
   - 总数：24 个
   - 人数：6 人
   - 每人：24 ÷ 6 = 4 个
   答案：每人 4 个橘子

Q: {new_question}
A:
"""
```

**优点**：质量更高，格式可控
**缺点**：需要精心设计示例

#### Internal CoT / System 2 Reasoning (2025 新趋势)

随着 **OpenAI o1** 和 **DeepSeek-R1** 等推理模型（Reasoning Models）的出现，CoT 正在从"提示词技巧"演变为"模型内在能力"。

- **原理**：模型在输出最终答案前，会先在内部生成并未对用户展示的隐式思维链（Internal Thoughts）。
- **变化**：对于这类模型，用户**不再需要**手动编写 "Let's think step by step"，模型会自动进行长链路推理。
- **最佳实践**：对 o1 类模型，Prompt 应保持简单直接，过多的 Few-Shot 指导反而可能干扰其内在推理逻辑。

#### Self-Consistency CoT

多次采样，取最一致的答案：

```python
answers = []
for _ in range(5):
    response = model.generate(prompt, temperature=0.7)
    answers.append(extract_answer(response))

# 投票选出最常见的答案
final_answer = most_common(answers)
```

**原理**：正确的推理路径更可能被多次发现
**适用场景**：高风险决策、追求高准确率

#### Tree of Thoughts

将推理过程组织成**树形结构**（详见下一节）：

```
                  问题
                   │
        ┌──────────┼──────────┐
        ↓          ↓          ↓
     思路A       思路B       思路C
       │          │           │
    ┌──┴──┐    ┌──┴──┐     ┌──┴──┐
    ↓     ↓    ↓     ↓     ↓     ↓
  步骤   步骤  步骤  步骤   步骤  步骤
```

### 2.1.3 任务规划

```python
def plan_task(goal: str) -> List[str]:
    prompt = f"""
    我需要完成以下目标：{goal}
    
    让我思考需要哪些步骤：
    1. 首先，我需要理解任务的核心要求...
    2. 然后，我应该确定所需的资源...
    3. 接下来，我需要...
    ...
    
    基于以上分析，具体的执行步骤是：
    """
    return model.generate(prompt)
```

### 2.1.4 工具选择

```python
def select_tool(task: str, available_tools: List[Tool]) -> Tool:
    prompt = f"""
    任务：{task}
    
    可用工具：
    {format_tools(available_tools)}
    
    让我分析应该使用哪个工具：
    1. 任务需要获取实时数据，所以需要联网能力
    2. 数据格式是 JSON，需要解析能力
    3. web_search 工具可以联网且返回结构化数据
    
    因此，最合适的工具是：web_search
    """
    return parse_tool_selection(model.generate(prompt))
```

### 2.1.5 错误诊断

```python
def diagnose_error(error: Exception, context: str) -> str:
    prompt = f"""
    执行过程中出现错误：{error}
    
    上下文信息：{context}
    
    让我分析可能的原因：
    1. 错误类型是 KeyError，说明访问了不存在的键
    2. 查看上下文，数据来自 API 响应
    3. API 可能返回了不同于预期的结构
    
    可能的解决方案：
    1. 添加键存在性检查
    2. 打印实际的 API 响应查看结构
    3. 使用 .get() 方法提供默认值
    """
    return model.generate(prompt)
```

#### 最佳实践

### 2.1.6 Prompt 设计

```python
# ✅ 好的 CoT Prompt
"""
请分析这个问题，在回答之前：
1. 首先识别问题的关键信息
2. 然后确定解决方法
3. 逐步执行计算或推理
4. 最后验证答案是否合理
"""

# ❌ 不好的 Prompt
"""
直接告诉我答案。
"""
```

### 2.1.7 控制输出格式

```python
prompt = """
请按以下格式回答：

<思考过程>
[在这里写出你的推理步骤]
</思考过程>

<最终答案>
[在这里给出简洁的答案]
</最终答案>
"""
```

### 2.1.8 与其他技术结合

- **CoT + RAG**：先检索相关知识，再进行推理
- **CoT + Few-Shot**：提供示例引导推理格式
- **CoT + Self-Consistency**：提高推理可靠性

#### 局限性

1. **增加延迟和成本**：更多的 token 意味着更长的响应时间和更高的费用
2. **可能引入错误**：错误的中间步骤会传播到最终答案
3. **对简单任务可能过度**：不是所有问题都需要复杂推理
4. **模型幻觉**：模型可能编造看似合理但错误的推理

### 2.1.9 小结

思维链是提升 AI 推理能力的基础技术。在设计 Agent 系统时，合理运用 CoT 可以：
- 提高复杂任务的完成质量
- 增强系统的可解释性
- 便于调试和错误追踪

下一节我们将探讨更高级的任务分解算法：Tree of Thoughts 和 Graph of Thoughts。

---

**下一节**: [2.2 Decomposition](2.2_decomposition.md)