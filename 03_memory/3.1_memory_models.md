## 3.1 记忆的认知模型：工作记忆 vs 长期记忆

#### 为什么 Agent 需要记忆？

大语言模型（LLM）的本质是无状态的函数。虽然最新的 Gemini 1.5 Pro 支持 1M+ 的上下文窗口，但在实际工程中，完全依赖 Context Window 面临三个挑战：
1.  **成本 (Cost)**：每次都把整本书塞进 Prompt，Token 费用极其高昂。
2.  **延迟 (Latency)**：处理长文本会导致首字生成延迟（TTFT）显著增加。
3.  **注意力稀释 (Lost in the Middle)**：研究表明，当上下文过长时，模型容易忽略中间的信息，只能记住开头和结尾。

因此，我们需要构建一个类似于人类大脑的记忆系统，让 Agent 能够**高效地存储**和**精准地检索**信息。

---

### 3.1.1 记忆的解剖学分类

受人类认知科学启发，Agent 的记忆通常被划分为以下几类：

#### 感官记忆 (Sensory Memory)
*   这是最瞬时的记忆，对应 Agent 接收到的原始输入（用户发来的文字、API 返回的 JSON、图片的像素数据）。
*   通常只在处理当前 Request 的瞬间存在，随后转化为短期记忆。

#### 短期记忆 (Short-Term / Working Memory)
*   **定义**：当前对话的上下文（Context）。
*   **载体**：LLM 的 Prompt。
*   **限制**：受限于模型的 Context Window (如 8k - 128k)。
*   **管理策略**：
    *   **FIFO (先进先出)**：当满了时，删掉最早的对话。
    *   **Summarization**：定期让 LLM 对前 10 轮对话进行摘要，用 100 字概括 1000 字的内容，释放空间。

#### 长期记忆 (Long-Term Memory)
*   **定义**：跨越 Session 存在的持久化知识。包括世界知识（World Knowledge）和情景记忆（Episodic Memory）。
*   **载体**：向量数据库 (Vector DB) 或 知识图谱 (Graph DB)。
*   **检索方式**：RAG (Retrieval-Augmented Generation)。

---

### 3.1.2 核心技术：RAG 与向量检索

**RAG** 是构建长期记忆的事实标准。其核心流程如下：

#### Step 1: 索引 (Indexing)
1.  **加载 (Load)**：读取 PDF、Markdown、Notion 等源文件。
2.  **切片 (Chunking)**：将长文切成小块（如每块 500 tokens）。切片策略很重要，切太碎会丢失语义，切太大包含噪声。
    *   *高级技巧*：**Parent Document Retriever** —— 索引时用小切片（精准），返回时给大父文档（上下文完整）。
3.  **嵌入 (Embedding)**：使用 Embedding 模型（如 OpenAI `text-embedding-3`, Cohere, BGE）将文本转化为高维向量（Vector）。相似意思的句子，在向量空间中距离更近。
4.  **存储 (Store)**：存入 Pinecone, Milvus, Qdrant, Weaviate 或 pgvector。

#### Step 2: 检索与生成 (Retrieval & Generation)
1.  **查询嵌入**：将用户的问题也转化为向量。
2.  **相似度搜索**：使用余弦相似度 (Cosine Similarity) 找出 Top-K 最相关的切片。
3.  **重排序 (Re-ranking)**：向量搜索只能看语义相似，未必看逻辑相关。使用 Re-rank 模型（如 Cohere Rerank）对 Top-K 结果进行精排，剔除不相关结果。
4.  **生成**：将筛选后的切片填入 System Prompt：“请根据以下背景知识回答用户问题...”。

---

### 3.1.3 进阶：知识图谱与混合检索

向量检索并非万能。它擅长模糊匹配，但不擅长处理精确的关系。
*   *问题*：用户问“马斯克的第二任妻子的母亲是谁？”。
*   *缺陷*：向量搜索可能搜到很多八卦新闻，但很难通过多跳推理找到确切的人名。

**知识图谱 (Knowledge Graph)** 存储的是结构化三元组 `(Elon Musk, married_to, Talulah Riley)`。结合 Knowledge Graph 和 Vector DB 的 **GraphRAG** 技术正在兴起：
*   先通过图谱找到实体链接关系。
*   再通过向量补充非结构化描述。
*   让 Agent 书写 Cypher 查询语句来查询图谱。

### 3.1.4 本节小结
记忆是 Agent 积累经验的基础。没有记忆，Agent 永远只是一个初出茅庐的新手；有了记忆，它才能成为懂你习惯、知识渊博的专家。未来的方向是 **MemGPT** 这样的原生记忆操作系统，将记忆管理封装为类似 OS 的 Page Management (分页管理)，让 Agent 自主决定记什么、忘什么。

---

**下一节**: [向量数据库选型：Pinecone、Weaviate、Chroma](3.2_vector_databases.md)