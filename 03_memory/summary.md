## 本章小结

## 核心要点回顾

### 记忆的认知模型

智能体的记忆系统可以借鉴人类认知科学的模型：

- **工作记忆**：容量有限但访问快速，对应当前对话上下文
- **长期记忆**：容量大但需要检索，分为情景记忆和语义记忆
- **记忆编码**：通过 Embedding 将文本转化为可检索的向量

### 向量数据库选型

| 场景 | 推荐方案 |
|------|----------|
| 快速原型/开发 | Chroma |
| 生产环境/无运维 | Pinecone |
| 自托管/混合检索 | Weaviate |
| 超大规模 | Milvus |

### RAG 最佳实践

1. **文档切分**：选择合适的粒度，保持语义完整
2. **检索优化**：查询扩展 + 重排序 + 混合检索
3. **生成优化**：精心设计的 Prompt + 诚实的不确定性表达
4. **评估体系**：使用 RAGAS 等工具持续评估

### 上下文管理

- **滑动窗口**：简单有效，适合大多数场景
- **摘要压缩**：平衡信息保留与空间节省
- **动态分配**：根据任务类型调整上下文预算

## 技术选型决策树

```
你需要什么类型的记忆？
│
├─ 仅当前会话 → 简单的消息列表
│
├─ 跨会话持久化
│   ├─ 小规模（< 10K）→ JSON/SQLite
│   └─ 大规模 → 向量数据库 or 图记忆
│       ├─ 追求简单 → Chroma
│       ├─ 追求托管 → Pinecone
│       ├─ 追求灵活 → Weaviate
│       └─ 追求关系推理 → Graphiti/Zep (TKG)
│
└─ 需要复杂检索
    ├─ 纯语义 → 向量检索
    ├─ 关系/时间推理 → 时序知识图谱
    ├─ 混合需求 → Weaviate / Elasticsearch
    └─ 结构化查询 → 传统数据库 + 向量索引
```

## 实践 Checklist

### 记忆系统设计 ✅

- [ ] 明确需要存储什么类型的记忆
- [ ] 选择合适的存储方案
- [ ] 设计记忆的索引和检索策略
- [ ] 规划记忆的更新和清理机制

### RAG 系统 ✅

- [ ] 选择合适的 Embedding 模型
- [ ] 设计文档切分策略
- [ ] 实现检索后重排序
- [ ] 设计带引用的生成 Prompt
- [ ] 建立评估流水线

### 上下文管理 ✅

- [ ] 计算各组件的 token 预算
- [ ] 实现上下文压缩策略
- [ ] 添加 token 使用监控
- [ ] 测试窗口溢出场景的处理

## 延伸阅读

- 论文：[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)
- 论文：[LongMem: Efficient Memory Augmentation for Long Context](https://arxiv.org/abs/2306.07174)
- 博客：[Building Production-Ready RAG Applications](https://www.pinecone.io/learn/series/rag/)

## 下一步

掌握了记忆系统后，下一章我们将探讨智能体如何通过工具使用来扩展能力边界——从函数调用到 MCP 协议，从代码解释器到浏览器自动化。

---

**下一节**: [工具使用与环境交互](../04_tools/README.md)