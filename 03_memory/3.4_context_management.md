## 3.4 上下文窗口管理与压缩策略

大语言模型的上下文窗口是有限的资源。如何在有限的窗口中放入最有价值的信息，是构建高效智能体的关键挑战。

### 3.4.1 从 Prompt Engineering 到 Context Engineering

随着 Agent 系统的复杂度提升，单一的提示词工程（Prompt Engineering）已不足以应对挑战。我们需要升级到**上下文工程 (Context Engineering)** 的视角。

**上下文工程（Context Engineering）** 是一门管理大语言模型有限"注意力预算 (Attention Budget)"的学科。这就好比计算机的 RAM 管理，不仅要关注"写入什么"（Prompt），更要关注"保留什么"（Context）。

核心挑战在于 **"中间丢失" (Lost-in-the-Middle)** 现象：当上下文过长时，模型往往容易忽略中间部分的信息，而更关注开头和结尾。因此，Context Engineering 的目标是：**用最少的高信噪比 tokens，换取最高的任务成功率。**

### 3.4.2 主流模型的上下文限制

| 模型 | 上下文窗口 | 大约字数（中文）|
|------|------------|-----------------|
| GPT-5 | 256K tokens | ~128,000 字 |
| GPT-5-mini | 128K tokens | ~64,000 字 |
| Claude 4 Sonnet | 200K tokens | ~100,000 字 |
| Gemini 2.0 Pro | 2M tokens | ~1,000,000 字 |

### 3.4.3 上下文的构成

```
┌─────────────────────────────────────────────────────┐
│              上下文窗口 (Context Window)             │
│                                                     │
│  ┌─────────────────────────────────────────────┐   │
│  │ System Prompt (身份、规则、工具定义)          │   │
│  │ ~500-2000 tokens                             │   │
│  └─────────────────────────────────────────────┘   │
│                                                     │
│  ┌─────────────────────────────────────────────┐   │
│  │ 检索的知识/记忆                               │   │
│  │ ~1000-5000 tokens                            │   │
│  └─────────────────────────────────────────────┘   │
│                                                     │
│  ┌─────────────────────────────────────────────┐   │
│  │ 对话历史                                      │   │
│  │ ~2000-10000 tokens                           │   │
│  └─────────────────────────────────────────────┘   │
│                                                     │
│  ┌─────────────────────────────────────────────┐   │
│  │ 当前用户输入                                  │   │
│  │ ~100-1000 tokens                             │   │
│  └─────────────────────────────────────────────┘   │
│                                                     │
│  ┌─────────────────────────────────────────────┐   │
│  │ 预留给输出的空间                              │   │
│  │ ~1000-4000 tokens                            │   │
│  └─────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────┘
```

### 3.4.4 对话历史管理策略

#### 滑动窗口

最简单的策略：保留最近的 N 条消息。

```python
class SlidingWindowMemory:
    def __init__(self, max_messages: int = 20):
        self.messages = []
        self.max_messages = max_messages
    
    def add(self, message: dict):
        self.messages.append(message)
        if len(self.messages) > self.max_messages:
            self.messages.pop(0)  # 移除最早的消息
    
    def get_context(self) -> List[dict]:
        return self.messages
```

**优点**：简单、低成本
**缺点**：可能丢失重要的早期上下文

#### Token 预算管理

按 token 数量而非消息数量管理：

```python
import tiktoken

class TokenBudgetMemory:
    def __init__(self, max_tokens: int = 4000, model: str = "gpt-4o"):
        self.messages = []
        self.max_tokens = max_tokens
        self.encoder = tiktoken.encoding_for_model(model)
    
    def count_tokens(self, messages: List[dict]) -> int:
        total = 0
        for msg in messages:
            total += len(self.encoder.encode(msg['content']))
            total += 4  # 消息格式开销
        return total
    
    def add(self, message: dict):
        self.messages.append(message)
        self._trim()
    
    def _trim(self):
        while self.count_tokens(self.messages) > self.max_tokens:
            # 保留 system 消息，移除最早的用户/助手消息
            for i, msg in enumerate(self.messages):
                if msg['role'] != 'system':
                    self.messages.pop(i)
                    break
```

#### 重要性采样

保留重要的消息，移除不重要的：

```python
class ImportanceSamplingMemory:
    def __init__(self, max_tokens: int = 4000):
        self.messages = []
        self.importance_scores = []
        self.max_tokens = max_tokens
    
    def add(self, message: dict, importance: float = 0.5):
        """
        importance: 0.0-1.0，越高越重要
        - 1.0: 关键决策、用户明确要求记住的内容
        - 0.7: 重要的技术细节
        - 0.5: 普通对话
        - 0.3: 闲聊、确认性回复
        """
        self.messages.append(message)
        self.importance_scores.append(importance)
        self._trim()
    
    def _trim(self):
        while self._over_budget():
            # 找到重要性最低的非系统消息
            min_idx = -1
            min_score = float('inf')
            for i, (msg, score) in enumerate(zip(self.messages, self.importance_scores)):
                if msg['role'] != 'system' and score < min_score:
                    min_score = score
                    min_idx = i
            
            if min_idx >= 0:
                self.messages.pop(min_idx)
                self.importance_scores.pop(min_idx)
```

#### 对话摘要压缩

定期将历史对话压缩为摘要：

```python
class SummaryMemory:
    def __init__(self, llm, summary_threshold: int = 10):
        self.llm = llm
        self.messages = []
        self.summary = None
        self.summary_threshold = summary_threshold
    
    def add(self, message: dict):
        self.messages.append(message)
        
        # 当消息过多时，压缩为摘要
        if len(self.messages) > self.summary_threshold:
            self._compress()
    
    def _compress(self):
        # 保留最近的几条消息
        recent = self.messages[-3:]
        to_summarize = self.messages[:-3]
        
        # 生成摘要
        summary_prompt = f"""请将以下对话历史压缩为简洁的摘要，保留关键信息：

{self._format_messages(to_summarize)}

摘要："""
        
        new_summary = self.llm.generate(summary_prompt)
        
        # 合并新旧摘要
        if self.summary:
            self.summary = f"{self.summary}\n{new_summary}"
        else:
            self.summary = new_summary
        
        self.messages = recent
    
    def get_context(self) -> List[dict]:
        context = []
        if self.summary:
            context.append({
                "role": "system",
                "content": f"[对话历史摘要]\n{self.summary}"
            })
        context.extend(self.messages)
        return context
```

### 3.4.5 内容压缩技术

#### 提示词压缩

使用专门的压缩模型或算法：

```python
from llmlingua import PromptCompressor

compressor = PromptCompressor(model_name="microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank")

def compress_context(context: str, target_ratio: float = 0.5) -> str:
    """将上下文压缩到指定比例"""
    result = compressor.compress_prompt(
        context,
        rate=target_ratio,
        force_tokens=['重要', '关键'],  # 强制保留的词
    )
    return result['compressed_prompt']
```

#### 选择性信息提取

只提取与当前任务相关的信息：

```python
def extract_relevant_info(history: List[dict], current_query: str) -> str:
    """从历史中提取与当前查询相关的信息"""
    
    prompt = f"""以下是对话历史：

{format_history(history)}

当前用户问题：{current_query}

请提取与当前问题相关的关键信息（如有的话）："""

    return llm.generate(prompt)
```

#### 实体和事实提取

将对话转化为结构化知识：

```python
def extract_entities_and_facts(messages: List[dict]) -> dict:
    prompt = """从以下对话中提取结构化信息：

{conversation}

请按以下格式输出：
- 用户信息：[姓名、偏好、背景等]
- 讨论的主题：[主题列表]
- 达成的结论：[结论列表]
- 待办事项：[任务列表]
"""
    
    result = llm.generate(prompt)
    return parse_structured_info(result)
```

### 3.4.6 动态上下文管理：渐进式披露

在复杂的 Agent 系统中，一次性加载所有工具定义和技能说明极其浪费 Token。我们可以借鉴 UI 设计中的 **"渐进式披露" (Progressive Disclosure)** 理念：

> **原则**：Agent 初始状态只加载"技能目录"，只有当需要使用特定技能时，才加载该技能的详细上下文（Prompt、Examples）。

#### 实现模式：

1.  **Lightweight Registry**: 系统启动时，System Prompt 只包含技能名称和简短描述。
2.  **Lazy Loading**: 当 Router 决定调用某个技能时，动态注入该技能的详细指令。
3.  **Context Swapping**: 任务切换时，卸载旧技能的上下文，加载新技能的上下文。

这种类似"虚拟内存"的交换机制，可以让 Agent 在拥有海量技能的同时，保持轻量的上下文负载。

```mermaid
graph LR
    Start([任务开始]) --> Registry{检查技能目录}
    Registry -- 需要技能 A --> LoadA[动态加载技能 A\n(Prompt + Examples)]
    Registry -- 需要技能 B --> LoadB[动态加载技能 B\n(Prompt + Examples)]
    LoadA --> Execute[执行任务]
    LoadB --> Execute
    Execute --> Finish([任务结束])
    Execute -- 切换任务 --> Unload[卸载当前技能\n释放 Context]
    Unload --> Registry
    
    style Start fill:#f9f9f9,stroke:#333
    style Registry fill:#fff9c4,stroke:#fbc02d
    style LoadA fill:#e1f5fe,stroke:#0288d1
    style LoadB fill:#e1f5fe,stroke:#0288d1
    style Execute fill:#e8f5e9,stroke:#388e3c
    style Unload fill:#ffebee,stroke:#d32f2f
```

图 3-5：渐进式披露的工作流程

#### 动态上下文发现的实践模式

Cursor 团队在实践中总结了五种有效的动态上下文发现策略，这些策略在实际 A/B 测试中将 Agent Token 消耗减少了 46.9%。

**1. 长工具响应转文件**

第三方工具（Shell 命令、MCP 调用）可能返回巨大的 JSON 响应。常见做法是截断，但这会丢失关键信息。更好的方式是将输出写入临时文件，Agent 按需读取：

```python
# 传统做法：截断导致信息丢失
result = run_shell_command(cmd)[:MAX_TOKENS]

# 动态发现模式：写入文件，按需读取
output_file = write_to_temp(run_shell_command(cmd))
# Agent 使用 tail 检查末尾，需要时读取更多
```

**2. 历史对话作为可引用文件**

当上下文窗口耗尽触发摘要时，会丢失细节。将完整历史保存为可检索文件，Agent 可在摘要不足时回溯原文：

```
摘要后 Agent 上下文：
├── [摘要] 用户希望优化数据库查询...
│
└── [引用] 完整历史位于 .cache/chat_history_001.md
    │
    └── Agent 可按需 grep 或读取特定段落
```

**3. MCP 工具动态加载**

某些 MCP Server 包含数十个工具，每个都有冗长的描述。始终加载所有定义会造成严重的上下文膨胀。

```
静态模式（高 Token 消耗）：
├── Tool A 完整定义 (500 tokens)
├── Tool B 完整定义 (400 tokens)
├── Tool C 完整定义 (600 tokens)
└── ... 共 20 个工具 = ~10,000 tokens

动态发现模式（低 Token 消耗）：
├── 工具名索引：[A, B, C, ...] (~100 tokens)
│
└── Agent 识别需要 Tool B
    └── 动态加载 Tool B 定义 (400 tokens)
```

关键技术：每个 MCP Server 对应一个文件夹，工具定义作为文件存储。Agent 列出文件夹内容即可看到工具清单，需要时用 grep 或 jq 过滤具体定义。

**4. 终端会话作为文件**

将集成终端的输出同步到文件系统，Agent 可以直接问"为什么我的命令失败了？"而无需用户复制粘贴日志：

```
~/.cache/terminal/
├── session_001.log  # 终端会话 1 的完整历史
└── session_002.log  # 终端会话 2 的完整历史
```

这对长时间运行的服务器日志尤为有用——Agent 可以 grep 只提取相关输出，而非加载全部历史。

**5. 智能体技能（Agent Skills）按需披露**

Skills 采用三层结构：

| 层级 | 内容 | Token 成本 | 加载时机 |
|------|------|-----------|---------|
| 索引层 | 名称 + 描述 | ~100/skill | 始终加载 |
| 指令层 | 完整 SKILL.md | ~2000 | 任务匹配时 |
| 资源层 | 脚本、参考文档 | 不定 | 执行时按需 |

> [!TIP]
> **核心原则**：静态上下文（始终包含）应最小化，动态上下文（按需拉取）应最大化。文件系统是连接两者的桥梁——Agent 可以轻松发现和读取文件，但不必始终将内容加载到上下文。

### 3.4.7 核心策略：短对话优于长对话

> [!TIP]
> **最佳实践**：保持对话简短、专注，每个对话只做一件事。

#### 1. "醉酒"现象
随着上下文积累，Agent 会表现出类似醉酒的症状：遗忘指令、逻辑混乱、开始产生幻觉。这是因为信噪比随着无关信息的积累而降低。

#### 2. 重启阈值
不要等到 Token 耗尽才重启。
*   **最佳实践**：在上下文使用率达到 **15%-20%** 时，就应该考虑重启会话。
*   **成本考量**：长对话的总生成成本是指数级增长的（因为每次都要带上前文）。

#### 3. 任务拆解
将大任务拆解为一组相互关联的短对话：
1.  **调研对话**：只负责读代码，输出计划。
2.  **实现对话**：带着计划（作为 System Prompt 或第一条消息）进行编码。
3.  **测试对话**：带着代码变更进行测试和修复。

### 3.4.8 根据任务类型调整分配

```python
class DynamicContextManager:
    def __init__(self, total_budget: int = 8000):
        self.total_budget = total_budget
    
    def allocate(self, task_type: str) -> dict:
        """根据任务类型分配上下文预算"""
        
        allocations = {
            "code_generation": {
                "system": 500,
                "knowledge": 3000,  # 需要更多代码示例
                "history": 1000,
                "output": 3500
            },
            "conversation": {
                "system": 500,
                "knowledge": 1000,
                "history": 4000,   # 需要更多对话历史
                "output": 2500
            },
            "analysis": {
                "system": 500,
                "knowledge": 4000, # 需要更多背景资料
                "history": 1000,
                "output": 2500
            }
        }
        
        return allocations.get(task_type, allocations["conversation"])
```

### 3.4.9 优先级队列管理

```python
from heapq import heappush, heappop

class PriorityContextManager:
    def __init__(self, max_tokens: int = 4000):
        self.max_tokens = max_tokens
        self.items = []  # (priority, tokens, content)
    
    def add(self, content: str, priority: int, tokens: int):
        """priority 越大越重要"""
        heappush(self.items, (-priority, tokens, content))
    
    def build_context(self) -> str:
        """构建不超过预算的最优上下文"""
        selected = []
        current_tokens = 0
        
        # 按优先级取出
        temp = []
        while self.items:
            priority, tokens, content = heappop(self.items)
            temp.append((priority, tokens, content))
            
            if current_tokens + tokens <= self.max_tokens:
                selected.append(content)
                current_tokens += tokens
        
        # 恢复堆
        for item in temp:
            heappush(self.items, item)
        
        return "\n\n".join(selected)
```

### 3.4.10 实践建议

### 3.4.11 预算分配经验法则

| 组件 | 建议占比 | 说明 |
|------|----------|------|
| System Prompt | 5-10% | 精简但完整 |
| 检索知识 | 20-40% | 根据任务动态调整 |
| 对话历史 | 20-30% | 摘要 + 最近几轮 |
| 当前输入 | 5-15% | 通常用户输入不长 |
| 输出预留 | 20-30% | 确保模型有足够空间输出 |

### 3.4.12 监控和优化

```python
class ContextMonitor:
    def __init__(self):
        self.stats = []
    
    def log(self, context_tokens: int, output_tokens: int, task_type: str):
        self.stats.append({
            "context": context_tokens,
            "output": output_tokens,
            "task": task_type,
            "timestamp": datetime.now()
        })
    
    def analyze(self):
        """分析上下文使用模式"""
        avg_context = sum(s["context"] for s in self.stats) / len(self.stats)
        avg_output = sum(s["output"] for s in self.stats) / len(self.stats)
        
        print(f"平均上下文使用：{avg_context:.0f} tokens")
        print(f"平均输出长度：{avg_output:.0f} tokens")
        print(f"建议输出预留：{avg_output * 1.5:.0f} tokens")
```

### 3.4.13 小结

上下文窗口管理的核心原则：

1. **预算意识**：始终清楚每个组件消耗多少 tokens
2. **动态调整**：根据任务类型灵活分配资源
3. **压缩优先**：能压缩的信息尽量压缩
4. **保留核心**：关键信息永远不能被丢弃
5. **持续监控**：了解实际使用模式，持续优化

掌握上下文管理，是构建高效、经济的智能体系统的必备技能。

下一节我们将进入第四章，探讨智能体的工具使用与环境交互能力。

---

**下一节**: [本章小结](summary.md)