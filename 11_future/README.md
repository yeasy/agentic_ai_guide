# 第十一章 安全、伦理与未来

在本书的最后一章，将目光投向智能体的阴暗面和未来。随着智能体能力的增强，它们造成破坏的潜力也在增加。

如何确保智能体永远站在人类这一边？如何防止它们被恶意利用？当智能体拥有越来越多的自主权时，法律和伦理边界在哪里？未来的智能体 AI 将如何走向通用人工智能（AGI）？

## 学习目标

读完本章后，你将能够：

- 识别智能体系统的主要安全威胁，并为关键链路设计纵深防御
- 将对齐与风险控制落到可执行的评估、红队与上线治理流程
- 理解法律与伦理的主要争议点，并用工程机制提升可追溯性与责任清晰度

## 章节导读

- **[11.1 安全边界：提示词注入与防御策略](11.1_security.md)**
  - 智能体面临的安全威胁：提示词注入 (Prompt Injection)、越狱 (Jailbreak)、数据泄露、供应链攻击与多智能体攻击面。学习如何使用输入验证、应用层护栏 (Guardrails)、架构隔离与输出检测等技术构建多层防御体系。

- **[11.2 价值对齐与风险控制](11.2_alignment.md)**
  - 探讨“回形针最大化”思想实验。如何防止智能体为了达成目标而不择手段？介绍 Constitutional AI（宪法 AI）和红队测试（Red Teaming）技术。

- **[11.3 智能体的法律与伦理边界](11.3_ethics.md)**
  - 当 AI 智能体造成损害时，谁来负责？探讨智能体的法律地位、责任归属、以及 AI 治理的国际动态。

- **[11.4 迈向通用人工智能](11.4_agi_path.md)**
  - 展望未来技术趋势：端侧大模型、具身智能、Agent OS 的雏形。智能体是通往 AGI 的必经之路吗？讨论一种常见的“能力分级路线图”。

这是本书的最后一章。希望通过本书的学习，你已经掌握了构建智能体系统的核心知识，并能够在实践中运用这些技术创造真正有价值的 AI 应用。

---

**下一节**: [安全边界：提示词注入与防御策略](11.1_security.md)
