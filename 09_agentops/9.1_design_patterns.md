## 9.1 设计模式：从 Workflow 到 Agent

最成功的系统往往不是用最复杂的框架构建的，而是使用了简单、可组合的模式。智能体系统包括两种模式：**工作流 (Workflows)** 和 **智能体 (Agents)**。

- **工作流 (Workflows)**: 系统通过预定义的代码路径编排 LLM 和工具。路径是固定的，确定性强。
- **智能体 (Agents)**: LLM 动态控制流程和工具使用，拥有决策权。适应性强，但不可控性增加。

本节将详细解析这两种架构下的核心设计模式。

### 9.1.1 Workflows：确定性编排

当任务可以被清晰分解时，应优先使用 Workflow。它们能提供更高的可预测性。

#### 提示词链（Prompt Chaining）

最基础的模式。将任务分解为一系列线性步骤，上一步的输出作为下一步的输入。

- **适用场景**：文案生成后翻译、生成大纲后扩写。
- **优势**：极低的延迟，易于调试。

#### 路由（Routing）

根据输入内容的分类，将其导向不同的后续流程。

- **结构**：输入 (Input) -> 路由 (Router/Classifier) -> 分支 (Branch) A/B/C
- **适用场景**：客服分流（售后/投诉）、难易分流（小模型处理简单题）。

#### 并行化（Parallelization）

利用 LLM 并行处理能力，提升速度或质量。

- **切片（Sectioning）**：将大任务切成独立的子任务并行处理（如同时审查代码的安全性、性能、风格）。
- **投票（Voting）**：同一任务运行多次，通过投票减少幻觉（如让 3 个模型分别找 Bug，取交集）。

#### 编排者-工作者（Orchestrator-Workers）

由于子任务无法预知（如"修改某个功能涉及哪几个文件"），需要一个中心编排者 (Orchestrator) 动态分析任务，然后分派给具体的 Worker LLMs 执行。

- **适用场景**：复杂编码任务、多源信息调研。
- **区别**：与传统的规划者 (Planner) 模式类似，但更强调编排者 (Orchestrator) 在执行过程中的动态分派与结果汇总 (Synthesize)。

#### 评估者-优化者（Evaluator-Optimizer）

即经典的 **反思 (Reflection)** 模式。

- **流程**：生成器 (Generator) 生成初稿 -> 评估者 (Evaluator) 提出修改意见 -> 生成器 (Generator) 优化 -> 循环。
- **适用场景**：高质量翻译、复杂代码生成。人类作家写书也是这个过程。

### 9.1.2 智能体：动态决策

当无法预定义路径时，我们需要让 LLM 接管控制权。

#### ReAct 与工具调用 (Tool Use)

智能体处于一个循环中：思考 (Thought) -> 调用工具 (Action) -> 观察结果 (Observation)。如第 2 章所述，这种"边想边做"的模式是智能体规划的核心范式（详见 [2.3 节](../02_reasoning/2.3_react.md)）。

- **核心**：智能体必须从环境中获取 **基本事实 (Ground Truth)** 来修正下一步行动。这也是 **简洁 (Simplicity)** 原则的体现。

#### 自主智能体（Autonomous Agents）

在受信任的环境中（如沙箱），赋予智能体更高的自主权。它不仅执行单步指令，还能自行规划长序列操作，甚至在遇到错误时自我恢复。

- **关键**：需要极强的 **工具定义 (Tool Definition)** 和 **防错设计 (Poka-yoke)**。
- **适用场景**：开放式探索（"找出系统中的所有漏洞"）、长期运行的任务。

### 9.1.3 如何选择

建议遵循 **"尽量简化"** 原则：

1. **从提示词链开始**：如果能用简单的提示词链解决，就不要用智能体。
2. **需要决策时用路由**。
3. **任务复杂时先试编排者-工作者**。
4. **只有在需要极高灵活性和处理开放世界问题时，才使用自主智能体**。

增加复杂性意味着增加延迟和成本，必须确保它能带来相应的效果提升。

### 9.1.4 模式与框架的对应

| 模式 | LangGraph 实现 | AutoGen 实现 | 备注 |
| :--- | :--- | :--- | :--- |
| **路由** | Conditional Edges | GroupChat Manager | 基础控制流 |
| **并行化** | Map-Reduce (Fan-out) | - | 提升效率 |
| **编排者** | StateGraph (Supervisor) | Two-Agent / GroupChat | 解决复杂任务首选 |
| **评估者** | Cycle Graph (A <-> B) | Nested Chat | 提升质量首选 |
| **智能体** | `prebuilt.create_react_agent` | `AssistantAgent` | 动态应对未知 |

智能体设计的艺术，就在于根据业务场景，灵活组合这些模式。例如，你完全可以构建一个 Workfow，其中某一步是一个 ReAct 智能体，做完后进入 Evaluator-Optimizer 环节。

### 9.1.5 行业最佳实践

随着 Agentic AI Foundation (AAIF) 的成立和行业标准化进程的推进，各大 AI 厂商也总结出了一套成熟的智能体设计最佳实践。

#### Anthropic 的智能体设计原则

Anthropic 在 Claude 智能体 SDK 中推广以下设计模式：

1. **核心智能体循环**
   ```
   收集上下文 → 采取行动 → 验证工作 → 重复
   ```

2. **给 Claude 一台"计算机"**
   - 提供 bash 命令执行能力
   - 提供文件编辑和创建能力
   - 提供 Web 访问能力

3. **智能体技能（Agent Skills）**
   - 将领域专业知识封装为可动态加载的"技能"
   - 技能包含指令、脚本和资源文件
   - 智能体可根据任务需求自动发现和加载技能

4. **CLAUDE.md 项目记忆**
   - 类似 AGENTS.md，用于存储项目约定和架构笔记
   - 作为 Claude 的持久化参考文档

#### OpenAI 的 Guardrails 最佳实践

OpenAI 在其智能体开发指南中强调"护栏"的重要性：

1. **分层护栏**
   - **输入层**：验证和过滤用户输入
   - **行为层**：限制智能体可执行的操作范围
   - **输出层**：审计和过滤智能体输出

2. **人类监督机制**
   - 高风险操作需人工确认
   - 敏感任务触发审批流程
   - 拒绝执行明显危险操作

3. **最小权限原则**
   - 只授予智能体完成任务所需的最小权限
   - 限制数据源访问范围
   - 沙箱化执行环境

#### Google 的智能体安全指南

Google Cloud 在智能体开发工具包 (ADK) 中集成了以下安全机制：

1. **模型装甲（Model Armor）**
   - 防止 Prompt 注入攻击
   - 检测数据泄露风险
   - 防范工具投毒（Tool Poisoning）

2. **自动发现与保护**
   - 自动发现运行中的智能体和 MCP 服务器
   - 识别潜在漏洞
   - 提供实时保护

3. **可观测性**
   - 全链路追踪 (Tracing) 智能体执行过程
   - 监控异常行为
   - 记录审计日志

### 9.1.6 跨厂商共识

尽管各厂商有不同的实现细节，但在以下原则上达成了共识：

| 原则 | 说明 |
|------|------|
| **透明性** | 智能体的决策过程应可解释和可追溯 |
| **可控性** | 人类应能随时介入和终止智能体行为 |
| **安全性** | 默认采用最小权限，敏感操作需确认 |
| **可审计** | 所有操作应记录日志以供审计 |
| **互操作** | 遵循开放标准（如 MCP）实现跨平台协作 |

> [!TIP]
> 建议参考 AAIF 官网 (https://aaif.io) 获取最新的行业标准和最佳实践文档。

### 9.1.7 系统设计优先于模型能力

2025 年发表的研究《[Why Do Multi-Agent LLM Systems Fail?](https://arxiv.org/abs/2503.13657)》通过分析 1642 条执行轨迹，揭示了一个反直觉的发现：**多智能体系统的失败更多源于组织设计缺陷，而非模型能力不足**。

#### 关键数据

- 7 个主流 MAS 框架的失败率在 **41%-86.7%** 之间
- 在相同模型（GPT-4o）下，MetaGPT 比 ChatDev 在系统设计问题（FC1）和协调问题（FC2）上减少了 **60-68%** 的失败
- 仅通过优化提示词设计（不更换模型），可提升 **15.6%** 的任务成功率

#### 设计启示

这一发现与组织行为学的研究一致：即使是由能力出众的个体组成的团队，如果组织结构存在缺陷，也可能导致灾难性失败。对于智能体系统设计者而言：

1. **先优化架构，再考虑换模型**：在更换更强模型之前，先检查系统设计是否存在问题
2. **明确工作流边界**：清晰定义每个智能体的输入输出规范和终止条件
3. **引入验证环节**：在关键步骤后增加验证智能体，减少错误传播

> [!IMPORTANT]
> 投资于系统设计的改进往往比升级模型更具成本效益。

### 9.1.8 交互模式：IDE 集成

作为"编排者 (Orchestrator)"模式的终极体现，现代 IDE（如 Cursor）将智能体深度集成到了开发环境中。它们不仅仅是代码补全工具，而是实现了完整的 **计划 (Plan) -> 执行 (Act) -> 反思 (Reflect)** 循环。

**主要模式体现**：

1.  **规划者 (Planner) 模式**：IDE 能够扫描全库，生成实施计划 (Implementation Plan)，经人类批准后执行（参见 **计划模式 (Plan Mode)**）。
2.  **上下文管理 (Context Management)**：通过 `@` 符号动态引用文件 (Files)、文件夹 (Folders)、文档 (Docs) 甚至 Git 历史 (Git History)，实现了精准的上下文注入。
3.  **记忆 (Memory)**：通过 `.cursor/rules` (规则) 和 `.cursor/plans` (计划) 实现项目级记忆。

> [!TIP]
> 关于 Cursor 的详细配置、Plan Mode 工作流、以及调试模式的具体操作，请参阅 **[10.3.1 Cursor](../10_agentic_coding/10.3_tools.md)**。

### 9.1.9 复利工程（Compounding Engineering）

传统的 AI 编程是线性的 (Prompt -> Code)，而 **复利工程 (Compounding Engineering)** 致力于构建具有记忆的系统。

#### 核心循环

1.  **问题**: 遇到 Bug 或 Bad Case。
2.  **修复**: 修复代码。
3.  **学习**: 问自己“如何防止下次再犯？”
    *   更新 `AGENTS.md`（项目知识库）。
    *   添加 Linter 规则。
    *   更新系统提示词 (System Prompt)。

通过这种方式，智能体的每一次错误都成为系统进化的养料。三个月后，你的系统将包含成百上千条沉淀下来的“隐形知识”，这是通用模型无法比拟的护城河。

### 9.1.10 小结

- 简单的任务用 **路由 (Router)** + **ReAct**。
- 复杂的任务用 **规划者 (Planner)**。
- 要求高质量的任务用 **反思 (Reflection)**。
- 生产级部署遵循 **行业最佳实践** 和 **安全护栏**。

下一节我们将探讨如何对这些复杂的智能体系统进行监控和调试。

---

**下一节**: [可观测性 (Observability) 与调试](9.2_observability.md)
